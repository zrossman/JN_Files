{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba18b86c",
   "metadata": {},
   "source": [
    "# Titanic Survivor Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767027d1",
   "metadata": {},
   "source": [
    "In this project, we'll use data from the Titanic passengers and a random forest algorithm to predict which passengers survived and which didn't. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff3fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74e76d0",
   "metadata": {},
   "source": [
    "## Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f48a8903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          892         0       3   \n",
       "1          893         1       3   \n",
       "2          894         0       2   \n",
       "3          895         0       3   \n",
       "4          896         1       3   \n",
       "\n",
       "                                           Name     Sex   Age  SibSp  Parch  \\\n",
       "0                              Kelly, Mr. James    male  34.5      0      0   \n",
       "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
       "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
       "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
       "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
       "\n",
       "    Ticket     Fare Cabin Embarked  \n",
       "0   330911   7.8292   NaN        Q  \n",
       "1   363272   7.0000   NaN        S  \n",
       "2   240276   9.6875   NaN        Q  \n",
       "3   315154   8.6625   NaN        S  \n",
       "4  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/zacrossman/Downloads/Titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0231c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Survived     418 non-null    int64  \n",
      " 2   Pclass       418 non-null    int64  \n",
      " 3   Name         418 non-null    object \n",
      " 4   Sex          418 non-null    object \n",
      " 5   Age          332 non-null    float64\n",
      " 6   SibSp        418 non-null    int64  \n",
      " 7   Parch        418 non-null    int64  \n",
      " 8   Ticket       418 non-null    object \n",
      " 9   Fare         417 non-null    float64\n",
      " 10  Cabin        91 non-null     object \n",
      " 11  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 39.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c1ece",
   "metadata": {},
   "source": [
    "It looks like we have 327 null values in the 'Cabin' column, 86 in the 'Age' column, and one in the fare column. 327 is roughly 78% of the rows, so we'll just get rid of that column. To deal with the null age values, we'll just fill them in with the average age for the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a153ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_age = df['Age'].mean()\n",
    "df.fillna(average_age, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3432190",
   "metadata": {},
   "source": [
    "The 'PassengerId', 'Name', 'Embarked', and 'Ticket' columns aren't relevant for our prediction, so we can just drop those columns as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1963c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived         0\n",
      "Pclass           3\n",
      "Sex           male\n",
      "Age           34.5\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Fare        7.8292\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Name', 'Embarked', 'PassengerId', 'Ticket', 'Cabin'], axis = 1)\n",
    "print(df.iloc[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9f2da6",
   "metadata": {},
   "source": [
    "Now we have all of our relevant columns. Our algorithm can't process strings, so lets change all 'male' values to 1, and all 'female' values to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e7caee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived     0.0000\n",
      "Pclass       3.0000\n",
      "Sex          1.0000\n",
      "Age         34.5000\n",
      "SibSp        0.0000\n",
      "Parch        0.0000\n",
      "Fare         7.8292\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['Sex'].replace('female', 0, inplace = True)\n",
    "df['Sex'].replace('male', 1, inplace = True)\n",
    "print(df.iloc[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a64f132",
   "metadata": {},
   "source": [
    "Now lets turn our feature columns and our label columns into arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58b801a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(['Survived'], axis = 1))\n",
    "y = np.array(df['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b7bd79",
   "metadata": {},
   "source": [
    "## Training and Implementing our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78e6703",
   "metadata": {},
   "source": [
    "Now that our data is all set and converted into feature and label arrays, we can split the data into train and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bfa851c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: 334\n",
      "X_test size: 84\n",
      "y_train size: 334\n",
      "y_test size: 84\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 42)\n",
    "print('X_train size:', len(X_train))\n",
    "print('X_test size:', len(X_test))\n",
    "print('y_train size:', len(y_train))\n",
    "print('y_test size:', len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf6d04",
   "metadata": {},
   "source": [
    "We wanted our test set to be around 20% of the data, which turns out to be 84 in this case. Next we'll use scikit-learn and build our model. We'll stick with the defualt number of trees, which is 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a55451b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4614e3e6",
   "metadata": {},
   "source": [
    "Now lets evaluate our model on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d98223d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Accuracy: 1.0\n",
      "Training Data F1 Score: 1.0\n",
      "Training Data Confusion Matrix:\n",
      "[[216   0]\n",
      " [  0 118]]\n"
     ]
    }
   ],
   "source": [
    "rfc_pred_train = rfc.predict(X_train)\n",
    "print('Training Data Accuracy:', rfc.score(X_train, y_train))\n",
    "print('Training Data F1 Score:', f1_score(y_train, rfc_pred_train))\n",
    "train_cm = confusion_matrix(y_train, rfc_pred_train)\n",
    "print('Training Data Confusion Matrix:')\n",
    "print(train_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9b521",
   "metadata": {},
   "source": [
    "Now lets evaluate our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe11c2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Accuracy: 1.0\n",
      "Test Data F1 Score: 1.0\n",
      "Test Data Confusion Matrix:\n",
      "[[50  0]\n",
      " [ 0 34]]\n"
     ]
    }
   ],
   "source": [
    "rfc_pred_test = rfc.predict(X_test)\n",
    "print('Test Data Accuracy:', rfc.score(X_test, y_test))\n",
    "print('Test Data F1 Score:', f1_score(y_test, rfc_pred_test))\n",
    "test_cm = confusion_matrix(y_test, rfc_pred_test)\n",
    "print('Test Data Confusion Matrix:')\n",
    "print(test_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e71a7",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d628c9",
   "metadata": {},
   "source": [
    "Our random forest model was very accurate and was consistently hitting at 100%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a69004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
