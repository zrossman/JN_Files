{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2111c405",
   "metadata": {},
   "source": [
    "# Spam Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2373ee51",
   "metadata": {},
   "source": [
    "This program uses a multinomial naive bayes algorithm to determine whether an email is spam or ham (not spam). This is done by training the model to correlate certain words with ham and other words with spam through strict probabilty. The model, when fed with a test email, will calculate the probability that the email is spam and the probability it is ham independantly, and will classify the email as the one with the higher probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea66693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda22f5",
   "metadata": {},
   "source": [
    "## Basic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdf59ea",
   "metadata": {},
   "source": [
    "Lets read in the dataset and see what it's all about. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b472423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>ham</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>1947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>19</td>\n",
       "      <td>172</td>\n",
       "      <td>False</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.477</td>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>4223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.800</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "      <td>2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.551</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>True</td>\n",
       "      <td>2743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0             0.0              14.28            0.0           0.0   \n",
       "1             0.0               0.00            1.0           0.0   \n",
       "2             0.0               0.00            0.0           0.0   \n",
       "3             0.0               0.00            0.0           0.0   \n",
       "4             0.0               0.00            0.0           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.00             0.0               0.0                0.00   \n",
       "1           0.50             0.0               0.0                0.00   \n",
       "2           0.00             0.0               0.0                1.29   \n",
       "3           0.00             0.0               0.0                0.00   \n",
       "4           1.17             0.0               0.0                0.00   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_(  char_freq_[  \\\n",
       "0              0.0            0.00  ...        0.000          0.0   \n",
       "1              0.0            0.50  ...        0.357          0.0   \n",
       "2              0.0            0.43  ...        0.124          0.0   \n",
       "3              0.0            0.00  ...        0.000          0.0   \n",
       "4              0.0            1.17  ...        0.000          0.0   \n",
       "\n",
       "   char_freq_!  char_freq_$  char_freq_#  capital_run_length_average  \\\n",
       "0        0.000        0.000          0.0                       1.800   \n",
       "1        0.892        0.000          0.0                       2.000   \n",
       "2        0.310        0.062          0.0                       1.477   \n",
       "3        0.444        0.000          0.0                       2.800   \n",
       "4        0.000        0.000          0.0                       1.551   \n",
       "\n",
       "   capital_run_length_longest  capital_run_length_total    ham    Id  \n",
       "0                           5                         9   True  1947  \n",
       "1                          19                       172  False  2159  \n",
       "2                           8                        65  False  4223  \n",
       "3                           7                        28   True  2624  \n",
       "4                          10                        45   True  2743  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/zacrossman/Downloads/archive (3)/spam:ham.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270ad25d",
   "metadata": {},
   "source": [
    "As we can see from the first few rows here, this dataset is mostly comprised of the frequencies of certain words. Each row represents an email, and the word freq represents what percentage of the email is made up of that word. The data set has character frequencies as well. We can also see in the second to last column whether or not that particular email was ham or spam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff95273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3680, 59)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3680 entries, 0 to 3679\n",
      "Data columns (total 59 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   word_freq_make              3680 non-null   float64\n",
      " 1   word_freq_address           3680 non-null   float64\n",
      " 2   word_freq_all               3680 non-null   float64\n",
      " 3   word_freq_3d                3680 non-null   float64\n",
      " 4   word_freq_our               3680 non-null   float64\n",
      " 5   word_freq_over              3680 non-null   float64\n",
      " 6   word_freq_remove            3680 non-null   float64\n",
      " 7   word_freq_internet          3680 non-null   float64\n",
      " 8   word_freq_order             3680 non-null   float64\n",
      " 9   word_freq_mail              3680 non-null   float64\n",
      " 10  word_freq_receive           3680 non-null   float64\n",
      " 11  word_freq_will              3680 non-null   float64\n",
      " 12  word_freq_people            3680 non-null   float64\n",
      " 13  word_freq_report            3680 non-null   float64\n",
      " 14  word_freq_addresses         3680 non-null   float64\n",
      " 15  word_freq_free              3680 non-null   float64\n",
      " 16  word_freq_business          3680 non-null   float64\n",
      " 17  word_freq_email             3680 non-null   float64\n",
      " 18  word_freq_you               3680 non-null   float64\n",
      " 19  word_freq_credit            3680 non-null   float64\n",
      " 20  word_freq_your              3680 non-null   float64\n",
      " 21  word_freq_font              3680 non-null   float64\n",
      " 22  word_freq_000               3680 non-null   float64\n",
      " 23  word_freq_money             3680 non-null   float64\n",
      " 24  word_freq_hp                3680 non-null   float64\n",
      " 25  word_freq_hpl               3680 non-null   float64\n",
      " 26  word_freq_george            3680 non-null   float64\n",
      " 27  word_freq_650               3680 non-null   float64\n",
      " 28  word_freq_lab               3680 non-null   float64\n",
      " 29  word_freq_labs              3680 non-null   float64\n",
      " 30  word_freq_telnet            3680 non-null   float64\n",
      " 31  word_freq_857               3680 non-null   float64\n",
      " 32  word_freq_data              3680 non-null   float64\n",
      " 33  word_freq_415               3680 non-null   float64\n",
      " 34  word_freq_85                3680 non-null   float64\n",
      " 35  word_freq_technology        3680 non-null   float64\n",
      " 36  word_freq_1999              3680 non-null   float64\n",
      " 37  word_freq_parts             3680 non-null   float64\n",
      " 38  word_freq_pm                3680 non-null   float64\n",
      " 39  word_freq_direct            3680 non-null   float64\n",
      " 40  word_freq_cs                3680 non-null   float64\n",
      " 41  word_freq_meeting           3680 non-null   float64\n",
      " 42  word_freq_original          3680 non-null   float64\n",
      " 43  word_freq_project           3680 non-null   float64\n",
      " 44  word_freq_re                3680 non-null   float64\n",
      " 45  word_freq_edu               3680 non-null   float64\n",
      " 46  word_freq_table             3680 non-null   float64\n",
      " 47  word_freq_conference        3680 non-null   float64\n",
      " 48  char_freq_;                 3680 non-null   float64\n",
      " 49  char_freq_(                 3680 non-null   float64\n",
      " 50  char_freq_[                 3680 non-null   float64\n",
      " 51  char_freq_!                 3680 non-null   float64\n",
      " 52  char_freq_$                 3680 non-null   float64\n",
      " 53  char_freq_#                 3680 non-null   float64\n",
      " 54  capital_run_length_average  3680 non-null   float64\n",
      " 55  capital_run_length_longest  3680 non-null   int64  \n",
      " 56  capital_run_length_total    3680 non-null   int64  \n",
      " 57  ham                         3680 non-null   bool   \n",
      " 58  Id                          3680 non-null   int64  \n",
      "dtypes: bool(1), float64(55), int64(3)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7942157",
   "metadata": {},
   "source": [
    "We can see we have 3680 emails to work with. The 'capital_run' columns will not be of any use to us, so we will go ahead and get rid of them. The same goes for the Id column. the rest of our columns all contain 3680 non null values, which is perfect because that is how many emails we have, so we don't have to worry about any null values messing with our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b00559be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>19</td>\n",
       "      <td>172</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.477</td>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.800</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.551</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0             0.0              14.28            0.0           0.0   \n",
       "1             0.0               0.00            1.0           0.0   \n",
       "2             0.0               0.00            0.0           0.0   \n",
       "3             0.0               0.00            0.0           0.0   \n",
       "4             0.0               0.00            0.0           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.00             0.0               0.0                0.00   \n",
       "1           0.50             0.0               0.0                0.00   \n",
       "2           0.00             0.0               0.0                1.29   \n",
       "3           0.00             0.0               0.0                0.00   \n",
       "4           1.17             0.0               0.0                0.00   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0              0.0            0.00  ...          0.0        0.000   \n",
       "1              0.0            0.50  ...          0.0        0.357   \n",
       "2              0.0            0.43  ...          0.0        0.124   \n",
       "3              0.0            0.00  ...          0.0        0.000   \n",
       "4              0.0            1.17  ...          0.0        0.000   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.000        0.000          0.0   \n",
       "1          0.0        0.892        0.000          0.0   \n",
       "2          0.0        0.310        0.062          0.0   \n",
       "3          0.0        0.444        0.000          0.0   \n",
       "4          0.0        0.000        0.000          0.0   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       1.800                           5   \n",
       "1                       2.000                          19   \n",
       "2                       1.477                           8   \n",
       "3                       2.800                           7   \n",
       "4                       1.551                          10   \n",
       "\n",
       "   capital_run_length_total    ham  \n",
       "0                         9   True  \n",
       "1                       172  False  \n",
       "2                        65  False  \n",
       "3                        28   True  \n",
       "4                        45   True  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Id'], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49830cc2",
   "metadata": {},
   "source": [
    "Instead of deleting all the other columns we don't want, we'll just select the columns we do want when we convert our features and label into arrays, which we'll do next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16a0b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.loc[:, 'word_freq_make': 'char_freq_#'])\n",
    "y = np.array(df['ham'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fcdca5",
   "metadata": {},
   "source": [
    "Next, we'll split our data into training and testing subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aeebb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2944, 54) (2944,)\n",
      "\n",
      "Test data shape: (736, 54) (736,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=0)\n",
    "print('Training data shape:',X_train.shape, y_train.shape)\n",
    "print()\n",
    "print('Test data shape:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235a1207",
   "metadata": {},
   "source": [
    "We set our test size to .2%, so we'll use 2944 emails to train our model, and we'll test our model on the remaining 736 emails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f9f346",
   "metadata": {},
   "source": [
    "## Training and Implementing our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e298bc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a7f37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7cd7f1",
   "metadata": {},
   "source": [
    "Now lets evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8eafe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8559782608695652\n",
      "[ True  True False  True  True False  True  True  True  True]\n",
      "[[256  18]\n",
      " [ 88 374]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', classifier.score(X_test, y_test))\n",
    "print(y_test[:10])\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3d781e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Ham: 462\n",
      "Total Spam: 274\n"
     ]
    }
   ],
   "source": [
    "ham = 0\n",
    "spam = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == True:\n",
    "        ham += 1\n",
    "    else:\n",
    "        spam += 1\n",
    "\n",
    "print('Total Ham:', ham)\n",
    "print('Total Spam:', spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d526ca",
   "metadata": {},
   "source": [
    "Our model is filtering emails at around 86% accuracy, which is quite solid for this short and quick model. Now lets program a function that will take an email as an input, and output whether it is spam or ham. To do this, we first have to format the email in a way that our model is familiar with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e196b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formator(email):\n",
    "    a_list = [' ', '3','0', '6', '5', '8', '7', '4', '1', '9', 'q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', 'a',\n",
    "              's', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'z', 'x','c', 'v', 'b', 'n', 'm', 'Q', 'W', 'E', 'R', 'T', 'Y',\n",
    "              'U', 'I', 'O', 'P', 'A', 'S', 'D', 'F', 'G', 'H', 'J', 'K', 'L', 'Z', 'X', 'C', 'V', 'B', 'N', 'M', ';',\n",
    "              '(', '[','!', '$', '#']\n",
    "\n",
    "    #Deleting characters not included in our training data as well as puncuation so we can more easily split the email\n",
    "    #into words\n",
    "    for character in email:\n",
    "        if character not in a_list:\n",
    "            email = email.replace(character, '')\n",
    "\n",
    "    #Splitting our email into a list, where each element in the list is a word\n",
    "    email = email.split(' ') \n",
    "\n",
    "    #Counting the frequency of each word in the email\n",
    "    word_count = {}\n",
    "    for word in email:\n",
    "        if word in word_count:\n",
    "            word_count[word] += 1\n",
    "        else:\n",
    "            word_count[word] = 1\n",
    "\n",
    "    #These are the words and characters that are relevant for our model\n",
    "    relevant_words = ['make', 'address', 'all', '3d', 'our', 'over', 'remove', 'internet', 'order', 'mail', 'receive',\n",
    "                      'will', 'people', 'report', 'addresses', 'free', 'business' 'email', 'you', 'credit', 'your',\n",
    "                      'font', '000', 'money', 'hp', 'hpl', 'george', '650', 'lab', 'labs', 'telnet', '857', 'data',\n",
    "                      '415', '85', 'technology', '1999', 'parts', 'pm', 'direct', 'cs', 'meeting', 'original', 'project',\n",
    "                      're', 'edu', 'table', 'conference', ';', '(', '[', '!', '$', '#', '*']\n",
    "\n",
    "    #Here we parse through our relevant word list. If the word is in word_count, then we calculate the percent that \n",
    "    #that word makes up of the email, and append that percentage to final_format. If the word is not in word_count,\n",
    "    #then a 0% is appended to final_format for that word.\n",
    "    total_words = len(email)\n",
    "    final_format = []\n",
    "    for element in relevant_words:\n",
    "        if element in word_count:\n",
    "            percentage = word_count[element] / total_words\n",
    "            final_format.append(percentage)\n",
    "        else:\n",
    "            percentage = 0.0\n",
    "            final_format.append(percentage)\n",
    "    return final_format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0707643d",
   "metadata": {},
   "source": [
    "Now that our email has been converted to a list of percentages like our train data, we can convert it into an array and feed it to our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21b68b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spam_or_ham(email):\n",
    "    input = formator(email)\n",
    "    input_array = np.array(input)\n",
    "    input_array = np.reshape(input_array, (1, -1))\n",
    "    result = classifier.predict(input_array)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928ce40",
   "metadata": {},
   "source": [
    "Our function is built so that it returns 'True' if the prediction is ham, and 'False' if the prediction is spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4701df22",
   "metadata": {},
   "source": [
    "### Some Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7be22f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "#This is a very normal email and should be classified as ham\n",
    "ham_email = '''Good morning! How are you? I am just writing to you today to see how things are going and if you\n",
    "need anything. Let me know!'''\n",
    "print(spam_or_ham(ham_email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "406c7875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    }
   ],
   "source": [
    "#This is a very strange email that is obviously not written by a human, and is just asking for money. This should\n",
    "#be classified as spam\n",
    "spam_email = '''Please give us credit card and address so we can see if  qualify for our 'money now'\n",
    "program, where u receive money and rewards. Who doesn't like money money money! Thanks for business!'''\n",
    "print(spam_or_ham(spam_email))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
